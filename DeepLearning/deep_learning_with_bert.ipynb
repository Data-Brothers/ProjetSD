{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IokcyXzPoRpp"
   },
   "source": [
    "## Deep Learning for classification multi-classe\n",
    "\n",
    "\n",
    "1. Importation des bibliothèques Python + Préparation de l'environnement\n",
    "2. Importation et prétraitement des données\n",
    "3. Préparation de l'ensemble de données et du chargeur de données\n",
    "4. Création du réseau de neurones pour le Fine Tunning\n",
    "5. Ajustement du modèle\n",
    "6. Validation de la performance du modèle\n",
    "7. Sauvegarde du modèle et des artefacts pour l'avenir\n",
    "\n",
    "\n",
    "Model de language utilisé : `DistilBERT`\n",
    "\n",
    "* `DistilBERT`, c'est un modèle de transformer plus petit que `BERT` ou `RoBERTa`. Il est créé par un processus de distillation appliqué au modèle BERT :\n",
    "    * [Blog-Post](https://medium.com/huggingface/distilbert-8cf3380435b5)\n",
    "    * [Research Paper](https://arxiv.org/abs/1910.01108)\n",
    "    * [Documentation for python](https://huggingface.co/transformers/model_doc/distilbert.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1BH8d9PoRpv"
   },
   "source": [
    "## Importation des bibliothèques Python + Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQgzepmfoRp0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Pandas pour la gestion des données.\n",
    "\n",
    "import torch #Library Pytorch classique nécéssaire pour les modèles de Deep Learning.\n",
    "\n",
    "import transformers # Modèle Transformers sur lesquels reposent BERT+ variantess.\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader # Gestion des données dans Pytorch\n",
    "\n",
    "from transformers import DistilBertModel, DistilBertTokenizer # Modèle DisltilBERT et son tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuG-WbnfoRqS"
   },
   "source": [
    "### Initialisation de l'environement\n",
    "1. Si un `GPU` est disponible alors nous faisons tourner nos scripts sur `GPU` sinon on utilise le `CPU`.\n",
    "2. Définition de variables clés\n",
    "3. Création de `Dataset`==> définit la façon dont le texte est prétraité avant d'être envoyé au réseau de neurones.\n",
    "4. Définition de `Dataloader` ==> alimentera les données par lots au réseau pour un apprentissage et un traitement appropriés. \n",
    "\n",
    "Pour plus d'informations sur le Dataset et le Dataloader, consultez les [docs de PyTorch](https://pytorch.org/docs/stable/data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcfSXlSZoRqW",
    "outputId": "56c377a6-27b7-4d62-e5cc-072bec51cf9c"
   },
   "outputs": [],
   "source": [
    "# GPU ou CPU ?\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    # Dire à PyTorch d'utiliser le GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Il y a %d GPU(s) dispo.' % torch.cuda.device_count())\n",
    "    print('Nous utiliserons le GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('Aucun GPU dispo, utilisation du CPU à la place.')\n",
    "     # Dire à PyTorch d'utiliser le CPU. \n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "8661ef224c034689ba0136c9d3683d0e",
      "d640899169424c208f7c5d6279ddf848",
      "c082df79560d4d66b57106caff886fe6",
      "4d3c809b1f884fbea47882ada3bf38fc",
      "861dd4de32134005bb416ffd66fd6a2b",
      "3245beda46eb4f8087a7ec9220ec666b",
      "b8a6dfe0e4cb4ceebe13d1de61d3c8f1",
      "d8226c04bb194baa936e53eee67b433b"
     ]
    },
    "id": "rkt7KC9CoRqk",
    "outputId": "d4218309-ae71-4b96-d625-850333ec3271"
   },
   "outputs": [],
   "source": [
    "# Variables clés\n",
    "\n",
    "MAX_LEN = 512 #Longueur maximale d'une description\n",
    "TRAIN_BATCH_SIZE = 5 # Nombre d'éléments dans le batch d'apprentissage (combien d'éléments voir avant de calculer une iteration de descente de gradient)\n",
    "VALID_BATCH_SIZE = 10 # Nombre d'éléments dans le batch de validation\n",
    "EPOCHS = 1 # Nombre de passage du dataset complet\n",
    "LEARNING_RATE = 1e-05 #t_k dans la descente de gradient\n",
    "\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased') #Tokenizer de DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-PTve1-oRq0"
   },
   "source": [
    "## Classe `Triage` d'ensemble de données\n",
    "- Cette classe est définie pour accepter la Dataframe comme entrée et générer des sorties symboliques qui sont utilisées par le modèle DistilBERT pour la formation. \n",
    "- Nous utilisons le tokenizer DistilBERT pour tokeniser les données dans la colonne \"description\" de la dataframe. \n",
    "- Le tokenizer utilise la méthode `encode_plus` pour effectuer la tokenisation et générer les sorties nécessaires, à savoir : ids`, `attention_mask` (masque d'attention)\n",
    "- Pour en savoir plus sur le tokenizer, [se référer à ce document](https://huggingface.co/transformers/model_doc/distilbert.html#distilberttokenizer)\n",
    "- La \"cible\" est la catégorie codée sur le titre de la nouvelle. \n",
    "- La classe *Triage* est utilisée pour créer 2 ensembles de données, pour la formation et pour la validation.\n",
    "- L'ensemble de données pour la formation est utilisé pour affiner le modèle : **80 % des données d'origine**\n",
    "- *L'ensemble de données de validation* est utilisé pour évaluer la performance du modèle. Le modèle n'a pas vu ces données pendant la formation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffo6fMzooRq2"
   },
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        desc = str(self.data.description[index])\n",
    "        desc = \" \".join(desc.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            desc,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.Category[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mNrabrKr1P6",
    "outputId": "6cd3ea8b-2d0c-4f94-c403-3ff649a42353"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQGRbo7XoRrH",
    "outputId": "33dfa66d-2298-40c2-c676-8abd0cf5c10c"
   },
   "outputs": [],
   "source": [
    "df_X = pd.read_json('./data/train.json').set_index('Id')\n",
    "df_label=pd.read_csv('./data/train_label.csv').set_index('Id')\n",
    "\n",
    "df=pd.concat([df_X, df_label], axis=1).drop(['gender'],axis=1)\n",
    "\n",
    "\n",
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.85\n",
    "train_dataset=df.sample(frac=train_size)\n",
    "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwkmizYMoRrZ"
   },
   "source": [
    "\n",
    "#### Dataloader\n",
    "- `Dataloader` est utilisé pour créer un dataloader d'apprentissage et de validation qui charge les données dans le réseau. Ceci est nécessaire car toutes les données de l'ensemble de données ne peuvent pas être chargées dans la mémoire en une seule fois, d'où la nécessité de contrôler la quantité de données chargées dans la mémoire et ensuite transmises au réseau.\n",
    "- Ce contrôle est réalisé à l'aide de paramètres tels que `BATCH_SIZE` et `MAX_LEN`.\n",
    "- Les `Dataloaders` de formation et de validation sont utilisés respectivement dans la partie formation et validation du flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbkheXqzoRrc"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89tkpS64uvPv"
   },
   "source": [
    "#### F1 Score\n",
    "\n",
    "Pour évaluer notre modèle nous choisirons le f1 score.\n",
    "Nous créeons une classe F1Score car il n'est pas implémenté en pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-FxqYBmuutj"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class F1Score:\n",
    "    \"\"\"\n",
    "    Class for f1 calculation in Pytorch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, average: str = 'macro'):\n",
    "        \"\"\"\n",
    "        Init.\n",
    "\n",
    "        Args:\n",
    "            average: averaging method\n",
    "        \"\"\"\n",
    "        self.average = average\n",
    "        if average not in [None, 'micro', 'macro', 'weighted']:\n",
    "            raise ValueError('Wrong value of average parameter')\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_f1_micro(predictions: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate f1 micro.\n",
    "\n",
    "        Args:\n",
    "            predictions: tensor with predictions\n",
    "            labels: tensor with original labels\n",
    "\n",
    "        Returns:\n",
    "            f1 score\n",
    "        \"\"\"\n",
    "        true_positive = torch.eq(labels, predictions).sum().float()\n",
    "        f1_score = torch.div(true_positive, len(labels))\n",
    "        return f1_score\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_f1_count_for_label(predictions: torch.Tensor,\n",
    "                                labels: torch.Tensor, label_id: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Calculate f1 and true count for the label\n",
    "\n",
    "        Args:\n",
    "            predictions: tensor with predictions\n",
    "            labels: tensor with original labels\n",
    "            label_id: id of current label\n",
    "\n",
    "        Returns:\n",
    "            f1 score and true count for label\n",
    "        \"\"\"\n",
    "        # label count\n",
    "        true_count = torch.eq(labels, label_id).sum()\n",
    "\n",
    "        # true positives: labels equal to prediction and to label_id\n",
    "        true_positive = torch.logical_and(torch.eq(labels, predictions),\n",
    "                                          torch.eq(labels, label_id)).sum().float()\n",
    "        # precision for label\n",
    "        precision = torch.div(true_positive, torch.eq(predictions, label_id).sum().float())\n",
    "        # replace nan values with 0\n",
    "        precision = torch.where(torch.isnan(precision),\n",
    "                                torch.zeros_like(precision).type_as(true_positive),\n",
    "                                precision)\n",
    "\n",
    "        # recall for label\n",
    "        recall = torch.div(true_positive, true_count)\n",
    "        # f1\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        # replace nan values with 0\n",
    "        f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1).type_as(true_positive), f1)\n",
    "        return f1, true_count\n",
    "\n",
    "    def __call__(self, predictions: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate f1 score based on averaging method defined in init.\n",
    "\n",
    "        Args:\n",
    "            predictions: tensor with predictions\n",
    "            labels: tensor with original labels\n",
    "\n",
    "        Returns:\n",
    "            f1 score\n",
    "        \"\"\"\n",
    "\n",
    "        # simpler calculation for micro\n",
    "        if self.average == 'micro':\n",
    "            return self.calc_f1_micro(predictions, labels)\n",
    "\n",
    "        f1_score = 0\n",
    "        for label_id in range(1, len(labels.unique()) + 1):\n",
    "            f1, true_count = self.calc_f1_count_for_label(predictions, labels, label_id)\n",
    "\n",
    "            if self.average == 'weighted':\n",
    "                f1_score += f1 * true_count\n",
    "            elif self.average == 'macro':\n",
    "                f1_score += f1\n",
    "\n",
    "        if self.average == 'weighted':\n",
    "            f1_score = torch.div(f1_score, len(labels))\n",
    "        elif self.average == 'macro':\n",
    "            f1_score = torch.div(f1_score, len(labels.unique()))\n",
    "\n",
    "        return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CarkHk6uoRru"
   },
   "source": [
    "## Création du réseau de neurones pour le Fine Tunning\n",
    "\n",
    "Création d'un modèle personnalisé, en ajoutant le dropout (pour la régularisation) et une couche dense après le model `DistilBERT` pour obtenir le résultat final du modèle. \n",
    "\n",
    "Architecture :\n",
    "\n",
    "Modèle BERT ==> Couche Dense ==> Drop out ==> Couche Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nH7S_DkNoRry"
   },
   "outputs": [],
   "source": [
    "class DistillBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistillBERTClass, self).__init__()\n",
    "        # Définition des différentes couches du réseau\n",
    "        \n",
    "        # Couche du modèle DistilBERT\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        \n",
    "        # Couche dense\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        \n",
    "        # Module de Dropout\n",
    "        # `0.3` est la probabilité qu'un neurone soit remis à zéro. \n",
    "        self.dropout = torch.nn.Dropout(0.4) \n",
    "        \n",
    "        # Couche de classification\n",
    "        # `28` est le nombre de classe à prédire. \n",
    "        self.classifier = torch.nn.Linear(768, 28)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "05c5fc55c5454a01898d022d3ba4522a",
      "1e907b7401c44828a886eb11e2f0dac1",
      "5d0cda56693b4cda9d5c58df7dfc574c",
      "63827d8c7b644293b09d967f44d4aa9a",
      "a8b6a96453c34fa68b3d5d7651dc948a",
      "a27e092e730440f4890116e609b719b8",
      "200439a73c6040fdb5a6731ced626969",
      "0e71d37bac2842938ff4dceeb435e6d6",
      "2f5c4a7975e240a490e98dc9bfed3a5b",
      "414e0b1e3e8442c2bcd48da7794a7155",
      "bee44cb988a14d78a3907b6030d80353",
      "51aaaa9fcfea4b2fa89200732c1593b5",
      "268db9ed83cc4ae0ac6fc333a64419ec",
      "63f7777063aa4070bf88362b0b04477e",
      "1fdf09f17ebe4af3a6ca6d6ffbb5fcf5",
      "c292856ffdce4c128dfe1673573ff8f3"
     ]
    },
    "id": "2baaE8RCoRr4",
    "outputId": "45253c5d-4863-44e0-da31-f73e689c988c"
   },
   "outputs": [],
   "source": [
    "model = DistillBERTClass() #On instantie le modèle\n",
    "model.to(device) # On \"transfert\" le modèle vers le device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rnxCWySoRsG"
   },
   "source": [
    "## Création de la fonction de perte et de l'optimiseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8gNY-AeVoRsI"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss() ## Fonction de perte CrossEntropyLoss : https://www.baeldung.com/cs/cross-entropy + https://en.wikipedia.org/wiki/Cross_entropy\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUGzL8QZoRsQ"
   },
   "source": [
    "## Fine Tuning du Modèle\n",
    "\n",
    "\n",
    "Nous définissons ici une fonction `Train` qui entraîne le modèle sur l'ensemble de données d'apprentissage (`training_loader`), un nombre de fois spécifié (`EPOCH`) \n",
    "\n",
    "Les événements suivants se produisent dans cette fonction pour affiner le réseau de neurones :\n",
    "- L'explorateur de données transmet les données au modèle en fonction de la taille du lot. \n",
    "- Les sorties ultérieures du modèle et la catégorie réelle sont comparées pour calculer la perte. \n",
    "- La valeur de la perte est utilisée pour optimiser le poids des neurones dans le réseau.\n",
    "- La valeur de perte est imprimée dans la console tous les 5000 pas.\n",
    "\n",
    "Comme vous pouvez le voir, à une époque, à la dernière étape, le modèle fonctionnait avec une perte minuscule de 0,0002485, c'est-à-dire que la sortie est extrêmement proche de la sortie réelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_MsXhd2oRsS"
   },
   "outputs": [],
   "source": [
    "# Fonction de calcul du F1_score\n",
    "f1_metric=F1Score('macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDZ9zsj9oRsZ"
   },
   "outputs": [],
   "source": [
    "# Définition de la fonction d'apprentissage pour DistilBERT\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    # Initialisation\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    n_faux = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    \n",
    "    model.train() #On passe notre model en mode train en Pytorch\n",
    "    \n",
    "    for _,data in enumerate(training_loader, 0): # Pour chaque élement de notre jeu d'apprentissage \n",
    "        \n",
    "        # On rend disponible pour le GPU les indices, masques et valeurs cibles \n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        # On passe nos données dans le modèle\n",
    "        outputs = model(ids, mask)\n",
    "        # On calcul la perte\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        \n",
    "        # On calcul l'accuracy\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)       \n",
    "        MyF1_score=f1_metric(big_idx, targets)\n",
    "\n",
    "        print(f'F1_score: {MyF1_score}')\n",
    "        \n",
    "        # On augmente notre compteur d'étapes\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        #FF1=F1_Score(targets, big_idx,'macro')\n",
    "        #F1_tr.append(FF1)\n",
    "        \n",
    "        # Tout les 5000 descritpions on affiche la perte et la précision\n",
    "        if _%5000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            tp_step = (n_correct*100)/nb_tr_examples\n",
    "              \n",
    "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
    "            #print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
    "            #print(f\"Training F1_score per 5000 steps: {FF1}\")\n",
    "            \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    #print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "    #print(f\"Training F1_score Epoch: {FF1}\")\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5nRmLgXoRsj"
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_U0M1LioRsx"
   },
   "source": [
    "## Validation du modèle  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06SM_GgeoRsz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr=[]\n",
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0\n",
    "    \n",
    "    tr_loss = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask).squeeze()\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            \n",
    "            #n_correct += calcuate_accu(big_idx, targets)\n",
    "            MyF1_score=f1_metric(big_idx, targets)\n",
    "\n",
    "            print(f'F1_score: {MyF1_score}')\n",
    "\n",
    "            arr.append(MyF1_score)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            print(nb_tr_steps)\n",
    "            nb_tr_examples+=targets.size(0)\n",
    " \n",
    "    #FF1=f1_score(targets, big_idx, average='macro')\n",
    "    #print(f\"Training F1_score Epoch: {FF1}\")\n",
    "    return MyF1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjutMaLPoRs5",
    "outputId": "31b20d1b-16e3-4694-9cc9-2c357314cea6"
   },
   "outputs": [],
   "source": [
    "print('This is the validation section to print the accuracy and see how it performs')\n",
    "print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n",
    "\n",
    "acc = valid(model, testing_loader)\n",
    "print(\"Accuracy on test data = %0.2f%%\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Appqug7oRs-"
   },
   "outputs": [],
   "source": [
    "for item in f1arr:\n",
    "  item.compute()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ys4yojkKoRtD"
   },
   "outputs": [],
   "source": [
    "print(numpy.array(f1arr).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAUaGr1HoRtO"
   },
   "source": [
    "## Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yg4CrFwnoRtQ"
   },
   "outputs": [],
   "source": [
    "# Saving the files for re-use\n",
    "\n",
    "output_model_file = '/content/drive/My Drive/models/pytorch_distilbert_news.bin'\n",
    "output_vocab_file = '/content/drive/My Drive/models/vocab_distilbert_news.bin'\n",
    "\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "tokenizer.save_vocabulary(output_vocab_file)\n",
    "\n",
    "print('All files saved')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deep-learning-with-bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05c5fc55c5454a01898d022d3ba4522a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5d0cda56693b4cda9d5c58df7dfc574c",
       "IPY_MODEL_63827d8c7b644293b09d967f44d4aa9a"
      ],
      "layout": "IPY_MODEL_1e907b7401c44828a886eb11e2f0dac1"
     }
    },
    "0e71d37bac2842938ff4dceeb435e6d6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e907b7401c44828a886eb11e2f0dac1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fdf09f17ebe4af3a6ca6d6ffbb5fcf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "200439a73c6040fdb5a6731ced626969": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "268db9ed83cc4ae0ac6fc333a64419ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2f5c4a7975e240a490e98dc9bfed3a5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bee44cb988a14d78a3907b6030d80353",
       "IPY_MODEL_51aaaa9fcfea4b2fa89200732c1593b5"
      ],
      "layout": "IPY_MODEL_414e0b1e3e8442c2bcd48da7794a7155"
     }
    },
    "3245beda46eb4f8087a7ec9220ec666b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "414e0b1e3e8442c2bcd48da7794a7155": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d3c809b1f884fbea47882ada3bf38fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8226c04bb194baa936e53eee67b433b",
      "placeholder": "​",
      "style": "IPY_MODEL_b8a6dfe0e4cb4ceebe13d1de61d3c8f1",
      "value": " 232k/232k [00:00&lt;00:00, 788kB/s]"
     }
    },
    "51aaaa9fcfea4b2fa89200732c1593b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c292856ffdce4c128dfe1673573ff8f3",
      "placeholder": "​",
      "style": "IPY_MODEL_1fdf09f17ebe4af3a6ca6d6ffbb5fcf5",
      "value": " 268M/268M [00:10&lt;00:00, 24.9MB/s]"
     }
    },
    "5d0cda56693b4cda9d5c58df7dfc574c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a27e092e730440f4890116e609b719b8",
      "max": 442,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8b6a96453c34fa68b3d5d7651dc948a",
      "value": 442
     }
    },
    "63827d8c7b644293b09d967f44d4aa9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e71d37bac2842938ff4dceeb435e6d6",
      "placeholder": "​",
      "style": "IPY_MODEL_200439a73c6040fdb5a6731ced626969",
      "value": " 442/442 [00:26&lt;00:00, 16.4B/s]"
     }
    },
    "63f7777063aa4070bf88362b0b04477e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "861dd4de32134005bb416ffd66fd6a2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8661ef224c034689ba0136c9d3683d0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c082df79560d4d66b57106caff886fe6",
       "IPY_MODEL_4d3c809b1f884fbea47882ada3bf38fc"
      ],
      "layout": "IPY_MODEL_d640899169424c208f7c5d6279ddf848"
     }
    },
    "a27e092e730440f4890116e609b719b8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8b6a96453c34fa68b3d5d7651dc948a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b8a6dfe0e4cb4ceebe13d1de61d3c8f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bee44cb988a14d78a3907b6030d80353": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63f7777063aa4070bf88362b0b04477e",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_268db9ed83cc4ae0ac6fc333a64419ec",
      "value": 267967963
     }
    },
    "c082df79560d4d66b57106caff886fe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3245beda46eb4f8087a7ec9220ec666b",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_861dd4de32134005bb416ffd66fd6a2b",
      "value": 231508
     }
    },
    "c292856ffdce4c128dfe1673573ff8f3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d640899169424c208f7c5d6279ddf848": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8226c04bb194baa936e53eee67b433b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
